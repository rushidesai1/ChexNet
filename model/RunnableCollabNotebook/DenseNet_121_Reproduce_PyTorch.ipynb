{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DenseNet-121-Reproduce-PyTorch.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "kernelspec": {
      "display_name": "conda_pytorch_p36",
      "language": "python",
      "name": "conda_pytorch_p36"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "TOlhrZylRr4k",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Fetch Data"
      ]
    },
    {
      "metadata": {
        "id": "ZRTylx10Rr4n",
        "colab_type": "code",
        "colab": {},
        "outputId": "53b94389-6795-4c44-8fef-aa284e441dae"
      },
      "cell_type": "code",
      "source": [
        "!wget https://storage.googleapis.com/chestxray14/downsized/images_001.tar.gz \n",
        "!wget https://storage.googleapis.com/chestxray14/downsized/images_002.tar.gz \n",
        "!wget https://storage.googleapis.com/chestxray14/downsized/images_003.tar.gz \n",
        "!wget https://storage.googleapis.com/chestxray14/downsized/images_004.tar.gz \n",
        "!wget https://storage.googleapis.com/chestxray14/downsized/images_005.tar.gz \n",
        "!wget https://storage.googleapis.com/chestxray14/downsized/images_006.tar.gz \n",
        "!wget https://storage.googleapis.com/chestxray14/downsized/images_007.tar.gz \n",
        "!wget https://storage.googleapis.com/chestxray14/downsized/images_008.tar.gz \n",
        "!wget https://storage.googleapis.com/chestxray14/downsized/images_009.tar.gz \n",
        "!wget https://storage.googleapis.com/chestxray14/downsized/images_010.tar.gz \n",
        "!wget https://storage.googleapis.com/chestxray14/downsized/images_011.tar.gz \n",
        "!wget https://storage.googleapis.com/chestxray14/downsized/images_012.tar.gz"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-04-22 07:05:39--  https://storage.googleapis.com/chestxray14/downsized/images_001.tar.gz\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 172.217.164.176, 2607:f8b0:4004:803::2010\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|172.217.164.176|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 107261934 (102M) [application/x-gzip]\n",
            "Saving to: ‘images_001.tar.gz’\n",
            "\n",
            "images_001.tar.gz   100%[===================>] 102.29M   190MB/s    in 0.5s    \n",
            "\n",
            "2019-04-22 07:05:40 (190 MB/s) - ‘images_001.tar.gz’ saved [107261934/107261934]\n",
            "\n",
            "/content/images_01.tar.gz: Scheme missing.\n",
            "FINISHED --2019-04-22 07:05:40--\n",
            "Total wall clock time: 0.7s\n",
            "Downloaded: 1 files, 102M in 0.5s (190 MB/s)\n",
            "--2019-04-22 07:05:40--  https://storage.googleapis.com/chestxray14/downsized/images_002.tar.gz\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 172.217.7.208, 2607:f8b0:4004:801::2010\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|172.217.7.208|:443... connected.\n",
            "HTTP request sent, awaiting response... 404 Not Found\n",
            "2019-04-22 07:05:40 ERROR 404: Not Found.\n",
            "\n",
            "/content/images_02.tar.gz: Scheme missing.\n",
            "--2019-04-22 07:05:40--  https://storage.googleapis.com/chestxray14/downsized/images_003.tar.gz\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 172.217.15.80, 2607:f8b0:4004:815::2010\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|172.217.15.80|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 211959216 (202M) [application/x-gzip]\n",
            "Saving to: ‘images_003.tar.gz’\n",
            "\n",
            "images_003.tar.gz   100%[===================>] 202.14M  89.9MB/s    in 2.2s    \n",
            "\n",
            "2019-04-22 07:05:43 (89.9 MB/s) - ‘images_003.tar.gz’ saved [211959216/211959216]\n",
            "\n",
            "/content/images_03.tar.gz: Scheme missing.\n",
            "FINISHED --2019-04-22 07:05:43--\n",
            "Total wall clock time: 2.5s\n",
            "Downloaded: 1 files, 202M in 2.2s (89.9 MB/s)\n",
            "--2019-04-22 07:05:43--  https://storage.googleapis.com/chestxray14/downsized/images_004.tar.gz\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 172.217.8.16, 2607:f8b0:4004:810::2010\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|172.217.8.16|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 209022753 (199M) [application/x-gzip]\n",
            "Saving to: ‘images_004.tar.gz’\n",
            "\n",
            "images_004.tar.gz   100%[===================>] 199.34M  95.1MB/s    in 2.1s    \n",
            "\n",
            "2019-04-22 07:05:46 (95.1 MB/s) - ‘images_004.tar.gz’ saved [209022753/209022753]\n",
            "\n",
            "/content/images_04.tar.gz: Scheme missing.\n",
            "FINISHED --2019-04-22 07:05:46--\n",
            "Total wall clock time: 2.7s\n",
            "Downloaded: 1 files, 199M in 2.1s (95.1 MB/s)\n",
            "--2019-04-22 07:05:46--  https://storage.googleapis.com/chestxray14/downsized/images_005.tar.gz\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 172.217.15.80, 2607:f8b0:4004:815::2010\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|172.217.15.80|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 209817630 (200M) [application/x-gzip]\n",
            "Saving to: ‘images_005.tar.gz’\n",
            "\n",
            "images_005.tar.gz   100%[===================>] 200.10M  95.9MB/s    in 2.1s    \n",
            "\n",
            "2019-04-22 07:05:48 (95.9 MB/s) - ‘images_005.tar.gz’ saved [209817630/209817630]\n",
            "\n",
            "/content/images_05.tar.gz: Scheme missing.\n",
            "FINISHED --2019-04-22 07:05:48--\n",
            "Total wall clock time: 2.3s\n",
            "Downloaded: 1 files, 200M in 2.1s (95.9 MB/s)\n",
            "--2019-04-22 07:05:48--  https://storage.googleapis.com/chestxray14/downsized/images_006.tar.gz\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 172.217.15.112, 2607:f8b0:4004:801::2010\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|172.217.15.112|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 211634476 (202M) [application/x-gzip]\n",
            "Saving to: ‘images_006.tar.gz’\n",
            "\n",
            "images_006.tar.gz   100%[===================>] 201.83M  67.5MB/s    in 3.0s    \n",
            "\n",
            "2019-04-22 07:05:51 (67.5 MB/s) - ‘images_006.tar.gz’ saved [211634476/211634476]\n",
            "\n",
            "/content/images_06.tar.gz: Scheme missing.\n",
            "FINISHED --2019-04-22 07:05:51--\n",
            "Total wall clock time: 3.2s\n",
            "Downloaded: 1 files, 202M in 3.0s (67.5 MB/s)\n",
            "--2019-04-22 07:05:52--  https://storage.googleapis.com/chestxray14/downsized/images_007.tar.gz\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 172.217.7.240, 2607:f8b0:4004:810::2010\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|172.217.7.240|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 213039169 (203M) [application/x-gzip]\n",
            "Saving to: ‘images_007.tar.gz’\n",
            "\n",
            "images_007.tar.gz   100%[===================>] 203.17M  97.3MB/s    in 2.1s    \n",
            "\n",
            "2019-04-22 07:05:54 (97.3 MB/s) - ‘images_007.tar.gz’ saved [213039169/213039169]\n",
            "\n",
            "/content/images_07.tar.gz: Scheme missing.\n",
            "FINISHED --2019-04-22 07:05:54--\n",
            "Total wall clock time: 2.4s\n",
            "Downloaded: 1 files, 203M in 2.1s (97.3 MB/s)\n",
            "--2019-04-22 07:05:54--  https://storage.googleapis.com/chestxray14/downsized/images_008.tar.gz\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 172.217.164.176, 2607:f8b0:4004:811::2010\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|172.217.164.176|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 213568901 (204M) [application/x-gzip]\n",
            "Saving to: ‘images_008.tar.gz’\n",
            "\n",
            "images_008.tar.gz   100%[===================>] 203.67M   214MB/s    in 1.0s    \n",
            "\n",
            "2019-04-22 07:05:55 (214 MB/s) - ‘images_008.tar.gz’ saved [213568901/213568901]\n",
            "\n",
            "/content/images_08.tar.gz: Scheme missing.\n",
            "FINISHED --2019-04-22 07:05:55--\n",
            "Total wall clock time: 1.1s\n",
            "Downloaded: 1 files, 204M in 1.0s (214 MB/s)\n",
            "--2019-04-22 07:05:55--  https://storage.googleapis.com/chestxray14/downsized/images_009.tar.gz\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 172.217.164.176, 2607:f8b0:4004:803::2010\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|172.217.164.176|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 218279051 (208M) [application/x-gzip]\n",
            "Saving to: ‘images_009.tar.gz’\n",
            "\n",
            "images_009.tar.gz   100%[===================>] 208.17M   193MB/s    in 1.1s    \n",
            "\n",
            "2019-04-22 07:05:56 (193 MB/s) - ‘images_009.tar.gz’ saved [218279051/218279051]\n",
            "\n",
            "/content/images_09.tar.gz: Scheme missing.\n",
            "FINISHED --2019-04-22 07:05:56--\n",
            "Total wall clock time: 1.2s\n",
            "Downloaded: 1 files, 208M in 1.1s (193 MB/s)\n",
            "--2019-04-22 07:05:57--  https://storage.googleapis.com/chestxray14/downsized/images_010.tar.gz\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 172.217.8.16, 2607:f8b0:4004:801::2010\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|172.217.8.16|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 222713957 (212M) [application/x-gzip]\n",
            "Saving to: ‘images_010.tar.gz’\n",
            "\n",
            "images_010.tar.gz   100%[===================>] 212.40M  96.2MB/s    in 2.2s    \n",
            "\n",
            "2019-04-22 07:05:59 (96.2 MB/s) - ‘images_010.tar.gz’ saved [222713957/222713957]\n",
            "\n",
            "/content/images_10.tar.gz: Scheme missing.\n",
            "FINISHED --2019-04-22 07:05:59--\n",
            "Total wall clock time: 2.5s\n",
            "Downloaded: 1 files, 212M in 2.2s (96.2 MB/s)\n",
            "--2019-04-22 07:05:59--  https://storage.googleapis.com/chestxray14/downsized/images_011.tar.gz\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 172.217.15.80, 2607:f8b0:4004:814::2010\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|172.217.15.80|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 223403949 (213M) [application/x-gzip]\n",
            "Saving to: ‘images_011.tar.gz’\n",
            "\n",
            "images_011.tar.gz   100%[===================>] 213.05M  87.6MB/s    in 2.4s    \n",
            "\n",
            "2019-04-22 07:06:02 (87.6 MB/s) - ‘images_011.tar.gz’ saved [223403949/223403949]\n",
            "\n",
            "/content/images_11.tar.gz: Scheme missing.\n",
            "FINISHED --2019-04-22 07:06:02--\n",
            "Total wall clock time: 2.7s\n",
            "Downloaded: 1 files, 213M in 2.4s (87.6 MB/s)\n",
            "--2019-04-22 07:06:02--  https://storage.googleapis.com/chestxray14/downsized/images_012.tar.gz\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 172.217.7.208, 2607:f8b0:4004:810::2010\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|172.217.7.208|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 152882814 (146M) [application/x-gzip]\n",
            "Saving to: ‘images_012.tar.gz’\n",
            "\n",
            "images_012.tar.gz   100%[===================>] 145.80M  99.6MB/s    in 1.5s    \n",
            "\n",
            "2019-04-22 07:06:04 (99.6 MB/s) - ‘images_012.tar.gz’ saved [152882814/152882814]\n",
            "\n",
            "/content/images_12.tar.gz: Scheme missing.\n",
            "FINISHED --2019-04-22 07:06:04--\n",
            "Total wall clock time: 1.7s\n",
            "Downloaded: 1 files, 146M in 1.5s (99.6 MB/s)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "rw0fily5Rr4w",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "-13d8wAaRr4x",
        "colab_type": "code",
        "colab": {},
        "outputId": "d6f151a4-7cf6-4359-c1f6-854366b657f9"
      },
      "cell_type": "code",
      "source": [
        "!rm -rf images\n",
        "!tar -xzf images_001.tar.gz\n",
        "!tar -xzf images_002.tar.gz\n",
        "!tar -xzf images_003.tar.gz\n",
        "!tar -xzf images_004.tar.gz\n",
        "!tar -xzf images_005.tar.gz\n",
        "!tar -xzf images_006.tar.gz\n",
        "!tar -xzf images_007.tar.gz\n",
        "!tar -xzf images_008.tar.gz\n",
        "!tar -xzf images_009.tar.gz\n",
        "!tar -xzf images_010.tar.gz\n",
        "!tar -xzf images_011.tar.gz\n",
        "!tar -xzf images_012.tar.gz"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tar (child): images_002.tar.gz: Cannot open: No such file or directory\n",
            "tar (child): Error is not recoverable: exiting now\n",
            "tar: Child returned status 2\n",
            "tar: Error is not recoverable: exiting now\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "AJ_SWqfgRr43",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!rm -rf *.gz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "X4wNefiRxABt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Fetch Labels"
      ]
    },
    {
      "metadata": {
        "id": "s4kfBf9mND02",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "outputId": "2c8bc263-bb51-4d75-f821-4d7d6c860d58"
      },
      "cell_type": "code",
      "source": [
        "!wget https://github.gatech.edu/raw/gist/rdesai65/e127e4cade5054eaadc8f886c7223e0a/raw/adeaaf5e4028007428b224266f820d43ec984e96/nih_labels.csv?token=AABESdCtB18y9CMnMHzcp38nd8WR1crdks5czoeRwA%3D%3D -O nih_labels.csv"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-04-28 07:06:33--  https://github.gatech.edu/raw/gist/rdesai65/e127e4cade5054eaadc8f886c7223e0a/raw/adeaaf5e4028007428b224266f820d43ec984e96/nih_labels.csv?token=AABESdCtB18y9CMnMHzcp38nd8WR1crdks5czoeRwA%3D%3D\n",
            "Resolving github.gatech.edu (github.gatech.edu)... 130.207.175.93\n",
            "Connecting to github.gatech.edu (github.gatech.edu)|130.207.175.93|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10817565 (10M) [text/plain]\n",
            "Saving to: ‘nih_labels.csv’\n",
            "\n",
            "nih_labels.csv      100%[===================>]  10.32M  38.2MB/s    in 0.3s    \n",
            "\n",
            "2019-04-28 07:06:33 (38.2 MB/s) - ‘nih_labels.csv’ saved [10817565/10817565]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ycN3pb4XRr45",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## ChexDataset"
      ]
    },
    {
      "metadata": {
        "id": "M-DgYyv4Rr46",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset\n",
        "import os\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "class ChexDataset(Dataset):\n",
        "\n",
        "    def __init__(\n",
        "            self,\n",
        "            path_to_images,\n",
        "            path_to_labels_csv,\n",
        "            fold,\n",
        "            transform=None,\n",
        "            sample=0,\n",
        "            label=\"any\",\n",
        "            sampled_images_path=None):\n",
        "\n",
        "        # temporary, if we figure out way to do this during pre-processing we dont need this\n",
        "        self.transform = transform\n",
        "        self.path_to_images = path_to_images\n",
        "        self.df = pd.read_csv(path_to_labels_csv)\n",
        "        self.df = self.df[self.df['fold'] == fold]  # filter all images belonging to this fold\n",
        "        \n",
        "        filenames = set([file for file in os.listdir('images') if file.endswith('.png')])\n",
        "        self.df = self.df.loc[self.df['Image Index'].isin(filenames)].reset_index(drop=True)\n",
        "\n",
        "        if sampled_images_path is not None:\n",
        "            sampled_images = pd.read_csv(sampled_images_path)\n",
        "            self.df = pd.merge(left=self.df, right=sampled_images, how=\"inner\", on=\"Image Index\")\n",
        "\n",
        "        # can limit to sample, useful for testing\n",
        "        # if fold == \"train\" or fold ==\"val\": sample=500\n",
        "        if 0 < sample < len(self.df):\n",
        "            self.df = self.df.sample(sample)\n",
        "\n",
        "        if not label == \"any\":  # can filter for positive findings of the kind described; useful for evaluation\n",
        "            if label in self.df.columns:\n",
        "                if len(self.df[self.df[label] == 1]) > 0:\n",
        "                    self.df = self.df[self.df[label] == 1]\n",
        "                else:\n",
        "                    print(\"No positive cases exist for \" + label + \", returning all unfiltered cases\")\n",
        "            else:\n",
        "                print(\"cannot filter on label \" + label +\n",
        "                      \" as not in data - please check spelling\")\n",
        "\n",
        "        self.df = self.df.set_index(\"Image Index\")\n",
        "        self.PRED_LABEL = [\n",
        "            'Atelectasis',\n",
        "            'Cardiomegaly',\n",
        "            'Effusion',\n",
        "            'Infiltration',\n",
        "            'Mass',\n",
        "            'Nodule',\n",
        "            'Pneumonia',\n",
        "            'Pneumothorax',\n",
        "            'Consolidation',\n",
        "            'Edema',\n",
        "            'Emphysema',\n",
        "            'Fibrosis',\n",
        "            'Pleural_Thickening',\n",
        "            'Hernia']\n",
        "        RESULT_PATH = \"results/\"\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "#         print(\"getItem: \"+ str(idx)+\"\\n\")\n",
        "\n",
        "        # read custom format\n",
        "        # convert to image format:\n",
        "\n",
        "        image = Image.open(\n",
        "            os.path.join(\n",
        "                self.path_to_images,\n",
        "                self.df.index[idx]))\n",
        "        image = image.convert('RGB')\n",
        "\n",
        "        label = np.zeros(len(self.PRED_LABEL), dtype=int)\n",
        "        for i in range(0, len(self.PRED_LABEL)):\n",
        "            # can leave zero if zero, else make one\n",
        "            if self.df[self.PRED_LABEL[i].strip()].iloc[idx].astype('int') > 0:\n",
        "                label[i] = self.df[self.PRED_LABEL[i].strip()\n",
        "                ].iloc[idx].astype('int')\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label, self.df.index[idx]\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Uqs6WVp2Rr48",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## EvaluateModel"
      ]
    },
    {
      "metadata": {
        "id": "0kbI29dERr48",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "# import ChexDataset as CXR\n",
        "from torchvision import transforms, utils\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, utils\n",
        "import sklearn\n",
        "import sklearn.metrics as sklm\n",
        "from torch.autograd import Variable\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def make_pred_multilabel(data_transforms, model, PATH_TO_IMAGES, PATH_TO_LABELS, use_gpu=False,test_sampled=0):\n",
        "    \"\"\"\n",
        "    Gives predictions for test fold and calculates AUCs using previously trained model\n",
        "    Args:\n",
        "        data_transforms: torchvision transforms to preprocess raw images; same as validation transforms\n",
        "        model: densenet-121 from torchvision previously fine tuned to training data\n",
        "        PATH_TO_IMAGES: path at which NIH images can be found\n",
        "    Returns:\n",
        "        pred_df: dataframe containing individual predictions and ground truth for each test image\n",
        "        auc_df: dataframe containing aggregate AUCs by train/test tuples\n",
        "    \"\"\"\n",
        "\n",
        "    # calc preds in batches of 16, can reduce if our GPU has less RAM\n",
        "    BATCH_SIZE = 16\n",
        "\n",
        "    # set model to eval mode; required for proper predictions given use of batchnorm\n",
        "    model.train(False)\n",
        "\n",
        "    # create data_loader\n",
        "#     dataset = CXR.ChexDataset(\n",
        "    dataset = ChexDataset(\n",
        "        path_to_images=PATH_TO_IMAGES,\n",
        "        path_to_labels_csv=PATH_TO_LABELS,\n",
        "        fold=\"test\",\n",
        "        transform=data_transforms['val'],\n",
        "        sample=test_sampled\n",
        "    )\n",
        "    data_loader = torch.utils.data.DataLoader(\n",
        "        dataset, BATCH_SIZE, shuffle=False, num_workers=8)\n",
        "    size = len(dataset)\n",
        "\n",
        "    # create empty dfs\n",
        "    pred_df = pd.DataFrame(columns=[\"Image Index\"])\n",
        "    true_df = pd.DataFrame(columns=[\"Image Index\"])\n",
        "\n",
        "    # iterate over data_loader\n",
        "    for i, data in enumerate(data_loader):\n",
        "\n",
        "        inputs, labels, _ = data\n",
        "        if use_gpu:\n",
        "          inputs, labels = Variable(inputs.cuda()), Variable(labels.cuda())\n",
        "\n",
        "        true_labels = labels.cpu().data.numpy()\n",
        "        batch_size = true_labels.shape\n",
        "\n",
        "        outputs = model(inputs)\n",
        "        probs = outputs.cpu().data.numpy()\n",
        "\n",
        "        # get predictions and true values for each item in batch\n",
        "        for j in range(0, batch_size[0]):\n",
        "            thisrow = {}\n",
        "            truerow = {}\n",
        "            thisrow[\"Image Index\"] = dataset.df.index[BATCH_SIZE * i + j]\n",
        "            truerow[\"Image Index\"] = dataset.df.index[BATCH_SIZE * i + j]\n",
        "\n",
        "            # iterate over each entry in prediction vector; each corresponds to\n",
        "            # individual label\n",
        "            for k in range(len(dataset.PRED_LABEL)):\n",
        "                thisrow[\"prob_\" + dataset.PRED_LABEL[k]] = probs[j, k]\n",
        "                truerow[dataset.PRED_LABEL[k]] = true_labels[j, k]\n",
        "\n",
        "            pred_df = pred_df.append(thisrow, ignore_index=True)\n",
        "            true_df = true_df.append(truerow, ignore_index=True)\n",
        "\n",
        "        if (i % 10 == 0):\n",
        "            print(str(i * BATCH_SIZE))\n",
        "\n",
        "    auc_df = pd.DataFrame(columns=[\"label\", \"auc\"])\n",
        "\n",
        "    # calc AUCs\n",
        "    for column in true_df:\n",
        "\n",
        "        if column not in [\n",
        "            'Atelectasis',\n",
        "            'Cardiomegaly',\n",
        "            'Effusion',\n",
        "            'Infiltration',\n",
        "            'Mass',\n",
        "            'Nodule',\n",
        "            'Pneumonia',\n",
        "            'Pneumothorax',\n",
        "            'Consolidation',\n",
        "            'Edema',\n",
        "            'Emphysema',\n",
        "            'Fibrosis',\n",
        "            'Pleural_Thickening',\n",
        "            'Hernia']:\n",
        "            continue\n",
        "        actual = true_df[column]\n",
        "        pred = pred_df[\"prob_\" + column]\n",
        "        thisrow = {}\n",
        "        thisrow['label'] = column\n",
        "        thisrow['auc'] = np.nan\n",
        "        try:\n",
        "            thisrow['auc'] = sklm.roc_auc_score(\n",
        "                actual.as_matrix().astype(int), pred.as_matrix())\n",
        "        except BaseException:\n",
        "            print(\"can't calculate auc for \" + str(column))\n",
        "        auc_df = auc_df.append(thisrow, ignore_index=True)\n",
        "\n",
        "    pred_df.to_csv(\"results/preds.csv\", index=False)\n",
        "    auc_df.to_csv(\"results/aucs.csv\", index=False)\n",
        "    return pred_df, auc_df\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qKXnGlDlRr4-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## ChexModel"
      ]
    },
    {
      "metadata": {
        "id": "byVk3_j4Rr4_",
        "colab_type": "code",
        "colab": {},
        "outputId": "0bb61ad7-b9ed-4739-87cc-e995ad4bbb36"
      },
      "cell_type": "code",
      "source": [
        "from __future__ import print_function, division\n",
        "\n",
        "# pytorch imports\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "from torch.autograd import Variable\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, utils\n",
        "\n",
        "# image imports\n",
        "from skimage import io, transform\n",
        "from PIL import Image\n",
        "\n",
        "# general imports\n",
        "import os\n",
        "import time\n",
        "from shutil import copyfile\n",
        "from shutil import rmtree\n",
        "\n",
        "# data science imports\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import csv\n",
        "\n",
        "# import ChexDataset as CXR\n",
        "# import EvaluateModel as EM\n",
        "\n",
        "use_gpu = torch.cuda.is_available()\n",
        "gpu_count = torch.cuda.device_count()\n",
        "print(\"Available GPU count:\" + str(gpu_count))\n",
        "\n",
        "\n",
        "def checkpoint(model, best_loss, epoch, LR):\n",
        "    \"\"\"\n",
        "    Saves checkpoint of torchvision model during training.\n",
        "\n",
        "    Args:\n",
        "        model: torchvision model to be saved\n",
        "        best_loss: best val loss achieved so far in training\n",
        "        epoch: current epoch of training\n",
        "        LR: current learning rate in training\n",
        "    Returns:\n",
        "        None\n",
        "    \"\"\"\n",
        "\n",
        "    print('saving')\n",
        "    state = {\n",
        "        'model': model,\n",
        "        'best_loss': best_loss,\n",
        "        'epoch': epoch,\n",
        "        'rng_state': torch.get_rng_state(),\n",
        "        'LR': LR\n",
        "    }\n",
        "\n",
        "    torch.save(state, 'results/checkpoint')\n",
        "\n",
        "\n",
        "def train_model(\n",
        "        model,\n",
        "        criterion,\n",
        "        optimizer,\n",
        "        learning_rate,\n",
        "        num_epochs,\n",
        "        data_loaders,\n",
        "        dataset_sizes,\n",
        "        weight_decay,\n",
        "        use_gpu = False\n",
        "):\n",
        "    \"\"\"\n",
        "    Fine tunes torchvision model to NIH CXR data.\n",
        "\n",
        "    Args:\n",
        "        model: torchvision model to be finetuned (densenet-121 in this case)\n",
        "        criterion: loss criterion (binary cross entropy loss, BCELoss)\n",
        "        optimizer: optimizer to use in training (SGD)\n",
        "        learning_rate: learning rate\n",
        "        num_epochs: continue training up to this many epochs\n",
        "        data_loaders: pytorch train and val dataloaders\n",
        "        dataset_sizes: length of train and val datasets\n",
        "        weight_decay: weight decay parameter we use in SGD with momentum\n",
        "    Returns:\n",
        "        model: trained torchvision model\n",
        "        best_epoch: epoch on which best model val loss was obtained\n",
        "\n",
        "    \"\"\"\n",
        "    since = time.time()\n",
        "\n",
        "    start_epoch = 1\n",
        "    best_loss = 999999\n",
        "    best_epoch = -1\n",
        "    last_train_loss = -1\n",
        "\n",
        "    # iterate over epochs\n",
        "    for epoch in range(start_epoch, num_epochs + 1):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs))\n",
        "        print('-' * 10)\n",
        "\n",
        "        # set model to train or eval mode based on whether we are in train or\n",
        "        # val; necessary to get correct predictions given batchnorm\n",
        "        for phase in ['train', 'val']:\n",
        "            print(\"Epoch {}/{}, phase:{}\".format(epoch, num_epochs, phase))\n",
        "            if phase == 'train':\n",
        "                model.train(True)\n",
        "            else:\n",
        "                model.train(False)\n",
        "\n",
        "            running_loss = 0.0\n",
        "\n",
        "            i = 0\n",
        "            total_done = 0\n",
        "#             print(\"Epoch {}/{}, phase:{}, start\".format(epoch, num_epochs, phase))\n",
        "            # iterate over all data in train/val dataloader:\n",
        "            for data in data_loaders[phase]:\n",
        "#                 print(\"for:\"+str(i))\n",
        "                i += 1\n",
        "                inputs, labels, _ = data\n",
        "#                 print(\"for-2:\")\n",
        "                batch_size = inputs.shape[0]\n",
        "#                 print(\"for-3:\")\n",
        "                labels = labels.float()\n",
        "#                 print(\"Epoch {}/{}, phase:{}, got input,labels\".format(epoch, num_epochs, phase))\n",
        "                if use_gpu:\n",
        "                  inputs = Variable(inputs.cuda())\n",
        "                  labels = Variable(labels.cuda()).float()\n",
        "                  \n",
        "#                 print(\"Epoch {}/{}, phase:{}, start-model(inputs)\".format(epoch, num_epochs, phase))                  \n",
        "                outputs = model(inputs)\n",
        "#                 print(\"Epoch {}/{}, phase:{}, end-model(inputs)\".format(epoch, num_epochs, phase))\n",
        "\n",
        "                # calculate gradient and update parameters in train phase\n",
        "#                 print(\"Epoch {}/{}, phase:{}, update grad\".format(epoch, num_epochs, phase))\n",
        "                optimizer.zero_grad()\n",
        "                loss = criterion(outputs, labels)\n",
        "                if phase == 'train':\n",
        "                    loss.backward()\n",
        "                    optimizer.step()\n",
        "#                 print(\"Epoch {}/{}, phase:{}, running_loss: {}\".format(epoch, num_epochs, phase, running_loss))\n",
        "#                 current_loss = \n",
        "#                 if loss.data[0]\n",
        "                running_loss += loss.item() * batch_size\n",
        "                print(\"Epoch {}/{}, phase:{}, running_loss: {}, current_loss: {}\".format(epoch, num_epochs, phase, running_loss, loss.item()))\n",
        "\n",
        "            epoch_loss = running_loss / dataset_sizes[phase]\n",
        "\n",
        "            if phase == 'train':\n",
        "                last_train_loss = epoch_loss\n",
        "\n",
        "            print(phase + ' epoch {}:loss {:.4f} with data size {}'.format(\n",
        "                epoch, epoch_loss, dataset_sizes[phase]))\n",
        "\n",
        "            # decay learning rate if no val loss improvement in this epoch\n",
        "            if phase == 'val' and epoch_loss > best_loss:\n",
        "                print(\"decay loss from \" + str(learning_rate) + \" to \" +\n",
        "                      str(learning_rate / 10) + \" as not seeing improvement in val loss\")\n",
        "                learning_rate = learning_rate / 10\n",
        "                # create new optimizer with lower learning rate\n",
        "                optimizer = optim.SGD(\n",
        "                    filter(\n",
        "                        lambda p: p.requires_grad,\n",
        "                        model.parameters()),\n",
        "                    lr=learning_rate,\n",
        "                    momentum=0.9,\n",
        "                    weight_decay=weight_decay)\n",
        "                print(\"created new optimizer with LR \" + str(learning_rate))\n",
        "\n",
        "            # checkpoint model if has best val loss yet\n",
        "            if phase == 'val' and epoch_loss < best_loss:\n",
        "                best_loss = epoch_loss\n",
        "                best_epoch = epoch\n",
        "                checkpoint(model, best_loss, epoch, learning_rate)\n",
        "\n",
        "            # log training and validation loss over each epoch\n",
        "            if phase == 'val':\n",
        "                with open(\"results/log_train\", 'a') as logfile:\n",
        "                    logw_riter = csv.writer(logfile, delimiter=',')\n",
        "                    if (epoch == 1):\n",
        "                        logw_riter.writerow([\"epoch\", \"train_loss\", \"val_loss\"])\n",
        "                    logw_riter.writerow([epoch, last_train_loss, epoch_loss])\n",
        "\n",
        "        total_done += batch_size\n",
        "        if total_done % (100 * batch_size) == 0:\n",
        "            print(\"completed \" + str(total_done) + \" so far in epoch\")\n",
        "\n",
        "        # break if no val loss improvement in 3 epochs\n",
        "        if (epoch - best_epoch) >= 3:\n",
        "            print(\"no improvement in 3 epochs, break\")\n",
        "            break\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
        "        time_elapsed // 60, time_elapsed % 60))\n",
        "\n",
        "    # load best model weights to return\n",
        "    checkpoint_best = torch.load('results/checkpoint')\n",
        "    model = checkpoint_best['model']\n",
        "\n",
        "    return model, best_epoch\n",
        "\n",
        "\n",
        "def train_cnn(PATH_TO_IMAGES, PATH_TO_LABELS, learning_rate, WEIGHT_DECAY, use_gpu=False,train_sampled=0,val_sampled=0,test_sampled=0, NUM_EPOCHS=8, BATCH_SIZE=16):\n",
        "    \"\"\"\n",
        "    Train torchvision model to NIH data given high level hyperparameters.\n",
        "\n",
        "    Args:\n",
        "        PATH_TO_IMAGES: path to NIH images\n",
        "        PATH_TO_LABELS: path to csv which contains labels\n",
        "        learning_rate: learning rate\n",
        "        WEIGHT_DECAY: weight decay parameter for SGD\n",
        "\n",
        "    Returns:\n",
        "        preds: torchvision model predictions on test fold with ground truth for comparison\n",
        "        aucs: AUCs for each train,test tuple\n",
        "\n",
        "    \"\"\"\n",
        "#     NUM_EPOCHS = 20\n",
        "#     BATCH_SIZE = 16\n",
        "\n",
        "    try:\n",
        "        rmtree('results/')\n",
        "    except BaseException:\n",
        "        pass  # directory doesn't yet exist, no need to clear it\n",
        "    os.makedirs(\"results/\")\n",
        "\n",
        "    # use imagenet mean,std for normalization\n",
        "    mean = [0.485, 0.456, 0.406]\n",
        "    std = [0.229, 0.224, 0.225]\n",
        "\n",
        "    N_LABELS = 14  # we are predicting 14 labels\n",
        "\n",
        "    # load labels\n",
        "    # df = pd.read_csv(\"nih_labels.csv\", index_col=0)\n",
        "\n",
        "    # define torchvision transforms\n",
        "    data_transforms = {\n",
        "        'train': transforms.Compose([\n",
        "            transforms.RandomHorizontalFlip(),      # Uncomment this line if flipping not done in preprocessing step\n",
        "            transforms.Scale(224),\n",
        "            # because scale doesn't always give 224 x 224, this ensures 224 x\n",
        "            # 224\n",
        "            transforms.CenterCrop(224),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean, std)\n",
        "        ]),\n",
        "        'val': transforms.Compose([\n",
        "            transforms.Scale(224),\n",
        "            transforms.CenterCrop(224),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean, std)\n",
        "        ]),\n",
        "    }\n",
        "\n",
        "    # create train/val data_loaders\n",
        "    transformed_datasets = {\n",
        "#         'train': CXR.ChexDataset(\n",
        "        'train': ChexDataset(        \n",
        "            path_to_images=PATH_TO_IMAGES,\n",
        "            path_to_labels_csv=PATH_TO_LABELS,\n",
        "            fold='train',\n",
        "            transform=data_transforms['train'],\n",
        "            sample=train_sampled\n",
        "        ),\n",
        "#         'val': CXR.ChexDataset(\n",
        "        'val': ChexDataset(\n",
        "            path_to_images=PATH_TO_IMAGES,\n",
        "            path_to_labels_csv=PATH_TO_LABELS,\n",
        "            fold='val',\n",
        "            transform=data_transforms['val'],\n",
        "            sample = val_sampled\n",
        "        )}\n",
        "\n",
        "    data_loaders = {\n",
        "        'train': torch.utils.data.DataLoader(\n",
        "            transformed_datasets['train'],\n",
        "            batch_size=BATCH_SIZE,\n",
        "            shuffle=True,\n",
        "            num_workers=8),\n",
        "        'val': torch.utils.data.DataLoader(\n",
        "            transformed_datasets['val'],\n",
        "            batch_size=BATCH_SIZE,\n",
        "            shuffle=True,\n",
        "            num_workers=8)}\n",
        "\n",
        "    # please do not attempt to train without GPU as will take excessively long\n",
        "    # if not use_gpu:\n",
        "    #     raise ValueError(\"Error, requires GPU\")\n",
        "    model = models.densenet121(pretrained=True)\n",
        "    num_features = model.classifier.in_features\n",
        "    # add final layer with # outputs in same dimension of labels with sigmoid\n",
        "    # activation\n",
        "    model.classifier = nn.Sequential(nn.Linear(num_features, N_LABELS), nn.Sigmoid())\n",
        "\n",
        "    # put model on GPU\n",
        "    if (use_gpu):\n",
        "        is_gpu_available = torch.cuda.is_available()\n",
        "        if not is_gpu_available:\n",
        "            raise ValueError(\"Error, Can't use GPU since hardware doesn't Support it, you idiot!\")\n",
        "        gpu_count = torch.cuda.device_count()\n",
        "        print(\"Using GPU: Available GPU count:\" + str(gpu_count))\n",
        "\n",
        "        model = model.cuda()\n",
        "\n",
        "    # define criterion, optimizer for training\n",
        "    criterion = nn.BCELoss()\n",
        "    optimizer = optim.SGD(\n",
        "        filter(\n",
        "            lambda p: p.requires_grad,\n",
        "            model.parameters()),\n",
        "        lr=learning_rate,\n",
        "        momentum=0.9,\n",
        "        weight_decay=WEIGHT_DECAY)\n",
        "    dataset_sizes = {x: len(transformed_datasets[x]) for x in ['train', 'val']}\n",
        "\n",
        "    # train model\n",
        "    model, best_epoch = train_model(model, criterion, optimizer, learning_rate, num_epochs=NUM_EPOCHS,\n",
        "                                    data_loaders=data_loaders, dataset_sizes=dataset_sizes, weight_decay=WEIGHT_DECAY)\n",
        "\n",
        "    # get preds and AUCs on test fold\n",
        "    preds,aucs = make_pred_multilabel(data_transforms, model, PATH_TO_IMAGES,PATH_TO_LABELS,test_sampled)\n",
        "\n",
        "    return preds,aucs\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Available GPU count:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "UQGs3xzfRr5B",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Train-Validate"
      ]
    },
    {
      "metadata": {
        "id": "RXCjrmmsRr5C",
        "colab_type": "code",
        "colab": {},
        "outputId": "67bbac13-c64b-4eea-855a-0c22995b595b"
      },
      "cell_type": "code",
      "source": [
        "PATH_TO_IMAGES = \"images/\"\n",
        "PATH_TO_LABELS = \"/content/nih_labels.csv\"\n",
        "WEIGHT_DECAY = 1e-4\n",
        "LEARNING_RATE = 0.01\n",
        "train_sampled=1\n",
        "test_sampled=1\n",
        "val_sampled=1\n",
        "EPOCHS = 1\n",
        "BATCH_SIZE = 16\n",
        "preds, aucs = train_cnn(PATH_TO_IMAGES, PATH_TO_LABELS, LEARNING_RATE, WEIGHT_DECAY, False,train_sampled, val_sampled, test_sampled, EPOCHS, BATCH_SIZE)\n",
        "# def         train_cnn(PATH_TO_IMAGES, PATH_TO_LABELS, learning_rate, WEIGHT_DECAY, use_gpu=False,train_sampled=0,val_sampled=0,test_sampled=0, NUM_EPOCHS=8, BATCH_SIZE=16):"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torchvision/transforms/transforms.py:188: UserWarning: The use of the transforms.Scale transform is deprecated, please use transforms.Resize instead.\n",
            "  \"please use transforms.Resize instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "----------\n",
            "Epoch 1/20, phase:train\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torchvision/models/densenet.py:212: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n",
            "  nn.init.kaiming_normal(m.weight.data)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20, phase:train, running_loss: 11.021450996398926, current_loss: 0.6888406872749329\n",
            "Epoch 1/20, phase:train, running_loss: 21.254274368286133, current_loss: 0.6395514607429504\n",
            "Epoch 1/20, phase:train, running_loss: 30.066996574401855, current_loss: 0.5507951378822327\n",
            "Epoch 1/20, phase:train, running_loss: 37.152626514434814, current_loss: 0.44285187125205994\n",
            "Epoch 1/20, phase:train, running_loss: 42.59288454055786, current_loss: 0.34001612663269043\n",
            "Epoch 1/20, phase:train, running_loss: 46.58354067802429, current_loss: 0.24941600859165192\n",
            "Epoch 1/20, phase:train, running_loss: 50.82808327674866, current_loss: 0.2652839124202728\n",
            "Epoch 1/20, phase:train, running_loss: 54.05667018890381, current_loss: 0.20178668200969696\n",
            "Epoch 1/20, phase:train, running_loss: 58.55576515197754, current_loss: 0.28119343519210815\n",
            "Epoch 1/20, phase:train, running_loss: 61.66197729110718, current_loss: 0.19413825869560242\n",
            "Epoch 1/20, phase:train, running_loss: 65.128586769104, current_loss: 0.21666309237480164\n",
            "Epoch 1/20, phase:train, running_loss: 68.57993268966675, current_loss: 0.2157091200351715\n",
            "Epoch 1/20, phase:train, running_loss: 72.66591119766235, current_loss: 0.25537365674972534\n",
            "Epoch 1/20, phase:train, running_loss: 76.4355161190033, current_loss: 0.2356003075838089\n",
            "Epoch 1/20, phase:train, running_loss: 79.36515593528748, current_loss: 0.18310248851776123\n",
            "Epoch 1/20, phase:train, running_loss: 84.20006442070007, current_loss: 0.30218178033828735\n",
            "Epoch 1/20, phase:train, running_loss: 86.01441192626953, current_loss: 0.11339671909809113\n",
            "Epoch 1/20, phase:train, running_loss: 90.18961095809937, current_loss: 0.2609499394893646\n",
            "Epoch 1/20, phase:train, running_loss: 93.7871105670929, current_loss: 0.22484372556209564\n",
            "Epoch 1/20, phase:train, running_loss: 97.683114528656, current_loss: 0.2435002475976944\n",
            "Epoch 1/20, phase:train, running_loss: 100.84172797203064, current_loss: 0.1974133402109146\n",
            "Epoch 1/20, phase:train, running_loss: 106.21416783332825, current_loss: 0.33577749133110046\n",
            "Epoch 1/20, phase:train, running_loss: 108.21153831481934, current_loss: 0.12483565509319305\n",
            "Epoch 1/20, phase:train, running_loss: 110.22377467155457, current_loss: 0.12576477229595184\n",
            "Epoch 1/20, phase:train, running_loss: 112.16059637069702, current_loss: 0.1210513561964035\n",
            "Epoch 1/20, phase:train, running_loss: 114.9204249382019, current_loss: 0.17248928546905518\n",
            "Epoch 1/20, phase:train, running_loss: 117.41952610015869, current_loss: 0.1561938226222992\n",
            "Epoch 1/20, phase:train, running_loss: 121.31824517250061, current_loss: 0.24366994202136993\n",
            "Epoch 1/20, phase:train, running_loss: 122.89643347263336, current_loss: 0.09863676875829697\n",
            "Epoch 1/20, phase:train, running_loss: 126.83547532558441, current_loss: 0.2461901158094406\n",
            "Epoch 1/20, phase:train, running_loss: 131.21110904216766, current_loss: 0.27347710728645325\n",
            "Epoch 1/20, phase:train, running_loss: 132.88756823539734, current_loss: 0.1047786995768547\n",
            "Epoch 1/20, phase:train, running_loss: 135.80610013008118, current_loss: 0.18240824341773987\n",
            "Epoch 1/20, phase:train, running_loss: 137.8751983642578, current_loss: 0.12931863963603973\n",
            "Epoch 1/20, phase:train, running_loss: 139.8004628419876, current_loss: 0.12032902985811234\n",
            "Epoch 1/20, phase:train, running_loss: 143.83407127857208, current_loss: 0.25210052728652954\n",
            "Epoch 1/20, phase:train, running_loss: 145.45681881904602, current_loss: 0.10142172127962112\n",
            "Epoch 1/20, phase:train, running_loss: 147.50877356529236, current_loss: 0.12824717164039612\n",
            "Epoch 1/20, phase:train, running_loss: 151.8082492351532, current_loss: 0.2687172293663025\n",
            "Epoch 1/20, phase:train, running_loss: 153.9074203968048, current_loss: 0.1311981976032257\n",
            "Epoch 1/20, phase:train, running_loss: 156.37686705589294, current_loss: 0.15434041619300842\n",
            "Epoch 1/20, phase:train, running_loss: 158.73144435882568, current_loss: 0.1471610814332962\n",
            "Epoch 1/20, phase:train, running_loss: 162.39068961143494, current_loss: 0.2287028282880783\n",
            "Epoch 1/20, phase:train, running_loss: 164.99904108047485, current_loss: 0.1630219668149948\n",
            "Epoch 1/20, phase:train, running_loss: 167.3498547077179, current_loss: 0.14692585170269012\n",
            "Epoch 1/20, phase:train, running_loss: 169.63917136192322, current_loss: 0.14308229088783264\n",
            "Epoch 1/20, phase:train, running_loss: 171.64762592315674, current_loss: 0.12552841007709503\n",
            "Epoch 1/20, phase:train, running_loss: 175.6687970161438, current_loss: 0.2513231933116913\n",
            "Epoch 1/20, phase:train, running_loss: 178.65798211097717, current_loss: 0.18682406842708588\n",
            "Epoch 1/20, phase:train, running_loss: 180.99489760398865, current_loss: 0.14605721831321716\n",
            "Epoch 1/20, phase:train, running_loss: 184.8338508605957, current_loss: 0.23993457853794098\n",
            "Epoch 1/20, phase:train, running_loss: 187.2717068195343, current_loss: 0.15236599743366241\n",
            "Epoch 1/20, phase:train, running_loss: 189.5061593055725, current_loss: 0.139653280377388\n",
            "Epoch 1/20, phase:train, running_loss: 191.0835872888565, current_loss: 0.09858924895524979\n",
            "Epoch 1/20, phase:train, running_loss: 193.47255289554596, current_loss: 0.14931035041809082\n",
            "Epoch 1/20, phase:train, running_loss: 196.56549775600433, current_loss: 0.19330905377864838\n",
            "Epoch 1/20, phase:train, running_loss: 198.59073984622955, current_loss: 0.12657763063907623\n",
            "Epoch 1/20, phase:train, running_loss: 199.84033262729645, current_loss: 0.07809954881668091\n",
            "Epoch 1/20, phase:train, running_loss: 203.50519049167633, current_loss: 0.22905361652374268\n",
            "Epoch 1/20, phase:train, running_loss: 204.75525951385498, current_loss: 0.07812931388616562\n",
            "Epoch 1/20, phase:train, running_loss: 209.85524034500122, current_loss: 0.31874880194664\n",
            "Epoch 1/20, phase:train, running_loss: 212.08598017692566, current_loss: 0.1394212394952774\n",
            "Epoch 1/20, phase:train, running_loss: 213.53400194644928, current_loss: 0.09050136059522629\n",
            "Epoch 1/20, phase:train, running_loss: 215.93781864643097, current_loss: 0.1502385437488556\n",
            "Epoch 1/20, phase:train, running_loss: 219.0743557214737, current_loss: 0.1960335671901703\n",
            "Epoch 1/20, phase:train, running_loss: 220.80093383789062, current_loss: 0.1079111322760582\n",
            "Epoch 1/20, phase:train, running_loss: 223.48947072029114, current_loss: 0.16803355515003204\n",
            "Epoch 1/20, phase:train, running_loss: 226.11259150505066, current_loss: 0.1639450490474701\n",
            "Epoch 1/20, phase:train, running_loss: 230.79881310462952, current_loss: 0.2928888499736786\n",
            "Epoch 1/20, phase:train, running_loss: 234.14295291900635, current_loss: 0.20900873839855194\n",
            "Epoch 1/20, phase:train, running_loss: 236.73819208145142, current_loss: 0.16220244765281677\n",
            "Epoch 1/20, phase:train, running_loss: 239.38942408561707, current_loss: 0.1657020002603531\n",
            "Epoch 1/20, phase:train, running_loss: 241.47620058059692, current_loss: 0.13042353093624115\n",
            "Epoch 1/20, phase:train, running_loss: 244.53424501419067, current_loss: 0.19112777709960938\n",
            "Epoch 1/20, phase:train, running_loss: 246.2342895269394, current_loss: 0.10625278204679489\n",
            "Epoch 1/20, phase:train, running_loss: 251.03212916851044, current_loss: 0.2998649775981903\n",
            "Epoch 1/20, phase:train, running_loss: 252.94662368297577, current_loss: 0.11965590715408325\n",
            "Epoch 1/20, phase:train, running_loss: 255.99267280101776, current_loss: 0.1903780698776245\n",
            "Epoch 1/20, phase:train, running_loss: 258.6707183122635, current_loss: 0.16737784445285797\n",
            "Epoch 1/20, phase:train, running_loss: 261.8181504011154, current_loss: 0.19671450555324554\n",
            "Epoch 1/20, phase:train, running_loss: 265.28068697452545, current_loss: 0.21640853583812714\n",
            "Epoch 1/20, phase:train, running_loss: 267.469730257988, current_loss: 0.13681520521640778\n",
            "Epoch 1/20, phase:train, running_loss: 270.16664230823517, current_loss: 0.16855700314044952\n",
            "Epoch 1/20, phase:train, running_loss: 272.802347779274, current_loss: 0.16473159193992615\n",
            "Epoch 1/20, phase:train, running_loss: 274.77923142910004, current_loss: 0.12355522811412811\n",
            "Epoch 1/20, phase:train, running_loss: 278.7155011892319, current_loss: 0.24601686000823975\n",
            "Epoch 1/20, phase:train, running_loss: 280.96756064891815, current_loss: 0.14075371623039246\n",
            "Epoch 1/20, phase:train, running_loss: 283.0221005678177, current_loss: 0.128408744931221\n",
            "Epoch 1/20, phase:train, running_loss: 285.02971827983856, current_loss: 0.12547610700130463\n",
            "Epoch 1/20, phase:train, running_loss: 286.97693502902985, current_loss: 0.12170104682445526\n",
            "Epoch 1/20, phase:train, running_loss: 290.3266056776047, current_loss: 0.20935441553592682\n",
            "Epoch 1/20, phase:train, running_loss: 292.64954817295074, current_loss: 0.14518390595912933\n",
            "Epoch 1/20, phase:train, running_loss: 295.9697712659836, current_loss: 0.2075139433145523\n",
            "Epoch 1/20, phase:train, running_loss: 299.5159250497818, current_loss: 0.2216346114873886\n",
            "Epoch 1/20, phase:train, running_loss: 301.76763904094696, current_loss: 0.14073212444782257\n",
            "Epoch 1/20, phase:train, running_loss: 304.1148475408554, current_loss: 0.14670053124427795\n",
            "Epoch 1/20, phase:train, running_loss: 305.75848519802094, current_loss: 0.10272735357284546\n",
            "Epoch 1/20, phase:train, running_loss: 308.42267167568207, current_loss: 0.1665116548538208\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "kB-V-pqRRr5E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 32
        },
        "outputId": "dfac5558-2433-4f4e-b782-3c0430f93f23"
      },
      "cell_type": "code",
      "source": [
        "print(\"Done\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Zgh7uSZkRr5F",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OvnhMb-0Rr5G",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}